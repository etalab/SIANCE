import spacy
from spacy.lang.fr import French


def prepare_sentencizer() -> spacy.language.Language:
    """
    Wrapper returning the spacy sentencizer for French language
    """
    nlp = French()
    nlp.add_pipe("sentencizer")
    return nlp


def prepare_sentencizer_training() -> spacy.language.Language:
    """
    This variant of sentencizer also cuts long sentences in shorter strings (e.g: ";" is considered as a separator)
    As a consequence, when only a few words are labelled by an inspector, the label can be expanded merely to the relevant part of the sentence
    """
    punct_chars = [
        "!",
        ".",
        "?",
        "Ö‰",
        "ØŸ",
        "Û”",
        "Ü€",
        "Ü",
        "Ü‚",
        "ß¹",
        "à¥¤",
        "à¥¥",
        "áŠ",
        "á‹",
        "á¢",
        "á§",
        "á¨",
        "á™®",
        "áœµ",
        "áœ¶",
        "á ƒ",
        "á ‰",
        "á¥„",
        "á¥…",
        "áª¨",
        "áª©",
        "áªª",
        "áª«",
        "á­š",
        "á­›",
        "á­",
        "á­Ÿ",
        "á°»",
        "á°¼",
        "á±¾",
        "á±¿",
        "â€¼",
        "â€½",
        "â‡",
        "âˆ",
        "â‰",
        "â¸®",
        "â¸¼",
        "ê“¿",
        "ê˜",
        "ê˜",
        "ê›³",
        "ê›·",
        "ê¡¶",
        "ê¡·",
        "ê£",
        "ê£",
        "ê¤¯",
        "ê§ˆ",
        "ê§‰",
        "ê©",
        "ê©",
        "ê©Ÿ",
        "ê«°",
        "ê«±",
        "ê¯«",
        "ï¹’",
        "ï¹–",
        "ï¹—",
        "ï¼",
        "ï¼",
        "ï¼Ÿ",
        "ğ©–",
        "ğ©—",
        "ğ‘‡",
        "ğ‘ˆ",
        "ğ‘‚¾",
        "ğ‘‚¿",
        "ğ‘ƒ€",
        "ğ‘ƒ",
        "ğ‘…",
        "ğ‘…‚",
        "ğ‘…ƒ",
        "ğ‘‡…",
        "ğ‘‡†",
        "ğ‘‡",
        "ğ‘‡",
        "ğ‘‡Ÿ",
        "ğ‘ˆ¸",
        "ğ‘ˆ¹",
        "ğ‘ˆ»",
        "ğ‘ˆ¼",
        "ğ‘Š©",
        "ğ‘‘‹",
        "ğ‘‘Œ",
        "ğ‘—‚",
        "ğ‘—ƒ",
        "ğ‘—‰",
        "ğ‘—Š",
        "ğ‘—‹",
        "ğ‘—Œ",
        "ğ‘—",
        "ğ‘—",
        "ğ‘—",
        "ğ‘—",
        "ğ‘—‘",
        "ğ‘—’",
        "ğ‘—“",
        "ğ‘—”",
        "ğ‘—•",
        "ğ‘—–",
        "ğ‘——",
        "ğ‘™",
        "ğ‘™‚",
        "ğ‘œ¼",
        "ğ‘œ½",
        "ğ‘œ¾",
        "ğ‘©‚",
        "ğ‘©ƒ",
        "ğ‘ª›",
        "ğ‘ªœ",
        "ğ‘±",
        "ğ‘±‚",
        "ğ–©®",
        "ğ–©¯",
        "ğ–«µ",
        "ğ–¬·",
        "ğ–¬¸",
        "ğ–­„",
        "ğ›²Ÿ",
        "ğªˆ",
        "ï½¡",
        "ã€‚",
        "\n\n",
        ";",
    ]
    config = {"punct_chars": punct_chars}
    nlp = French()
    nlp.add_pipe("sentencizer", config=config)
    return nlp
